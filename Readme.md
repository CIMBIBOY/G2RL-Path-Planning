# G2RL-Path-Planning
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/CIMBIBOY/G2RL-Path-Planning/blob/master/LICENSE)

# The present state of G2RL-Path-Planning is a work in progress. In case of constructive toughts please open an issue.

__Table of Contents__
- [Introduction](#introduction)
- [Setup](#setup)
- [Usage and Training](#usage-and-training)
- [Evaluation](#evaluation)
- [Improvements](#improvements)
- [References](#references)
- [Credits](#credits)

## Intorduction

Hey, my name is MÃ¡rk Czimber, I work as an intern at HUN-REN - SZTAKI, System and Control Theory Laboratory. 

G2RL-Path-Planning is an implementation of [arXiv paper](https://arxiv.org/abs/2005.05420) Mobile Robot Path Planning in Dynamic Environments through Globally Guided Reinforcement Learning.

I used open source code parts from [Tushar-ml/G2RL-Path-Planning](https://github.com/Tushar-ml/G2RL-Path-Planning) and [Yu-Haoyang/G2RL-Path-Planning](https://github.com/Yu-Haoyang/G2RL-Path-Planning), which provided some help to implement the paper. Thanks to them from afar!
 
My goal is to understand, experiment, improve or even supplement the implementation in order to promote the advancement of general robotics!

References: 
[1] Binyu Wang et al., 2020, Mobile Robot Path Planning in Dynamic Environments through Globally Guided Reinforcement Learning [arXiv:2005.05420](https://arxiv.org/abs/2005.05420)
[2] Qingbiao Li et al., 2019, Graph Neural Networks for Decentralized Multi-Robot Path Planning [arXiv:1912.06095](https://arxiv.org/abs/1912.06095)
[3] Tom Schaul et al., 2016, Prioritized Experience Replay [arXiv:1511.05952](https://arxiv.org/abs/1511.05952)

